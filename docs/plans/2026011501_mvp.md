# AG-UI Testing MVP - Implementation Plan

## Technology Stack (Recommended)

### Primary Language: TypeScript + Node.js

**Rationale:**

- Native SSE support via `fetch` API and `EventSource`
- Excellent YAML parsing libraries
- Strong typing for assertion logic
- Familiar to most AG-UI developers
- Good CLI tooling ecosystem
- Fast iteration for MVP

### Core Dependencies

| Purpose           | Library                      | Why                                              |
| ----------------- | ---------------------------- | ------------------------------------------------ |
| CLI framework     | `commander`                  | Lightweight, well-documented, TypeScript support |
| YAML parsing      | `js-yaml`                    | De facto standard, full YAML 1.2 support         |
| SSE client        | `eventsource` + native fetch | Reliable, handles reconnection                   |
| Schema validation | `zod`                        | Runtime validation with TypeScript inference     |
| Test runner       | `vitest`                     | Fast, ESM-native, good DX for internal tests     |
| Process execution | `execa`                      | Better child process handling for hooks          |
| Colors/output     | `picocolors`                 | Minimal, fast terminal colors                    |

### Project Structure

```
aguitest/
├── src/
│   ├── cli/
│   │   ├── index.ts          # Entry point
│   │   └── commands/
│   │       └── run.ts        # Main test runner command
│   ├── config/
│   │   ├── loader.ts         # Load aguitest.config.yaml
│   │   ├── schema.ts         # Zod schemas for config
│   │   └── interpolate.ts    # Variable interpolation (${VAR}, ${ENV.X})
│   ├── hooks/
│   │   └── executor.ts       # Run preflight hooks, parse JSON output
│   ├── client/
│   │   ├── agui.ts           # AG-UI SSE client
│   │   ├── events.ts         # Event type definitions
│   │   └── parser.ts         # Parse SSE events into structured data
│   ├── runner/
│   │   ├── test.ts           # Single test file executor
│   │   ├── turn.ts           # Turn execution logic
│   │   └── collector.ts      # Collect tool calls, text, timing
│   ├── assertions/
│   │   ├── engine.ts         # Assertion evaluation engine
│   │   ├── tools.ts          # Tool-related assertions
│   │   ├── timing.ts         # Timing assertions
│   │   ├── text.ts           # Text regex assertions
│   │   └── types.ts          # AssertBlock type definitions
│   ├── reporter/
│   │   ├── console.ts        # Console output (PASS/FAIL, details)
│   │   └── ci.ts             # CI-friendly output (exit codes, summary)
│   └── types/
│       ├── config.ts         # ProjectConfig types
│       ├── test.ts           # TestFile, Turn types
│       └── data.ts           # CapturedData, ToolCall types
├── bin/
│   └── aguitest             # Executable entry point
├── package.json
├── tsconfig.json
└── README.md
```

---

## Implementation Phases

### Phase 1: Foundation

**Goal:** Basic CLI that loads config and test files.

#### Tasks

1. **Project Setup**

   - Initialize Node.js project with TypeScript
   - Configure ESM module system
   - Set up build pipeline (tsup or esbuild)
   - Create bin entry point

2. **Config Loader**

   - Implement `aguitest.config.yaml` discovery (cwd, then parent dirs)
   - Define Zod schema for project config
   - Parse and validate config file
   - Environment variable interpolation (`${ENV.NAME}`)

3. **Test File Parser**

   - Define Zod schemas for test YAML structure
   - Parse test files from CLI arguments or glob patterns
   - Validate test file structure
   - Variable interpolation in test content

4. **CLI Scaffolding**
   - `aguitest run <glob>` - run matching test files
   - `aguitest run` - run all `*.test.yaml` files
   - `--config <path>` - override config file location
   - `--verbose` - detailed output

**Deliverable:** CLI that parses config and test files, reports validation errors.

---

### Phase 2: Execution Engine

**Goal:** Execute hooks and connect to AG-UI endpoint.

#### Tasks

1. **Hook Executor**

   - Spawn child process for each hook command
   - Capture stdout, parse as JSON
   - Merge parsed variables into context
   - Handle timeout (kill process, fail test)
   - Handle non-zero exit (fail test)

2. **Variable System**

   - Build variable map from: hook outputs + ENV
   - Implement `${VAR}` and `${ENV.NAME}` interpolation
   - Apply to endpoint URL and headers

3. **AG-UI SSE Client**

   - Connect to endpoint with interpolated headers
   - Parse AG-UI event stream
   - Handle connection errors gracefully
   - Implement reconnection logic (optional for MVP)

4. **Turn Execution**
   - Send user message to AG-UI endpoint
   - Collect events until assistant turn completes
   - Track turn boundaries (start/end timestamps)

**Deliverable:** CLI connects to AG-UI, sends messages, receives events.

---

### Phase 3: Data Collection

**Goal:** Capture and structure all observable data.

#### Tasks

1. **Tool Call Collector**

   - Parse `tool_call` events from SSE stream
   - Extract: name, args (normalized JSON), timestamp
   - Parse `tool_result` events
   - Match results to calls by ID
   - Store completion timestamp

2. **Text Collector**

   - Accumulate assistant text chunks
   - Store final assistant text per turn

3. **Turn Data Structure**

   - Build per-turn data object:
     ```typescript
     interface TurnData {
       turnIndex: number;
       toolCalls: ToolCall[];
       assistantText: string;
       startTs: number;
       endTs: number;
     }
     ```

4. **Test Data Aggregation**
   - Aggregate all turns into test-level data
   - Preserve ordering across turns
   - Calculate test-level timestamps

**Deliverable:** Complete data capture from AG-UI conversation.

---

### Phase 4: Assertion Engine

**Goal:** Evaluate all assertion types.

#### Tasks

1. **Assertion Engine Core**

   - Accept AssertBlock + captured data
   - Return pass/fail + detailed failure messages
   - Support both turn-level and test-level scope

2. **Tool Assertions**

   - `forbid`: Check no calls to forbidden tools
   - `require.name`: Check tool was called
   - `require.count`: exact / min / max validation
   - `require.args_match`: Regex match on arg values
   - `require.result_match`: Regex match on result
   - `require.result_not_match`: Negative regex match
   - `require.after`: Ordering validation
   - `forbid_calls`: Conditional forbid (args/result match)

3. **Timing Assertions**

   - `max_duration_ms`: Turn/test duration check
   - `max_gap_ms`: Gap between consecutive tool calls

4. **Text Assertions**

   - `must_match`: Regex match on assistant text
   - `must_not_match`: Negative regex match

5. **Failure Reporting**
   - Generate clear, actionable failure messages
   - Include expected vs actual values
   - Show which assertion failed and why

**Deliverable:** Full assertion evaluation with detailed failure output.

---

### Phase 5: Runner & Reporter

**Goal:** Orchestrate test execution and report results.

#### Tasks

1. **Test Runner**

   - Execute single test file end-to-end
   - Run hooks → turns → assertions
   - Fail fast on turn-level assertion failure
   - Continue to test-level assertions after all turns

2. **Multi-File Runner**

   - Discover test files from glob patterns
   - Run tests sequentially (MVP) or parallel (future)
   - Aggregate results across files

3. **Console Reporter**

   - Print test name and status (PASS/FAIL)
   - On failure: show which assertion failed
   - Show timing information
   - Color-coded output

4. **CI Reporter**
   - Exit code: 0 = all pass, 1 = any fail
   - Summary line for CI logs
   - Optional JSON output for tooling integration

**Deliverable:** Complete test runner with CI-friendly output.

---

### Phase 6: Polish & Documentation

**Goal:** Production-ready MVP.

#### Tasks

1. **Error Handling**

   - Graceful handling of network errors
   - Clear error messages for config issues
   - Timeout handling at all levels

2. **Documentation**

   - README with quick start
   - Config file reference
   - Test file reference
   - Assertion reference with examples

3. **Testing**

   - Unit tests for assertion logic
   - Integration tests with mock AG-UI server
   - Example test files

4. **Package & Publish**
   - npm package configuration
   - Binary distribution
   - Version management

---

## Key Implementation Details

### AG-UI SSE Event Types to Handle

Based on AG-UI protocol, expect these event types:

```typescript
type AGUIEvent =
  | { type: "TEXT_MESSAGE_START"; messageId: string }
  | { type: "TEXT_MESSAGE_CONTENT"; messageId: string; delta: string }
  | { type: "TEXT_MESSAGE_END"; messageId: string }
  | { type: "TOOL_CALL_START"; toolCallId: string; toolName: string }
  | { type: "TOOL_CALL_ARGS"; toolCallId: string; delta: string }
  | { type: "TOOL_CALL_END"; toolCallId: string }
  | { type: "TOOL_RESULT"; toolCallId: string; result: unknown }
  | { type: "RUN_STARTED"; runId: string }
  | { type: "RUN_FINISHED"; runId: string }
  | { type: "RUN_ERROR"; runId: string; error: string };
```

### Variable Interpolation

```typescript
function interpolate(template: string, vars: Record<string, string>): string {
  return template.replace(/\$\{(ENV\.)?(\w+)\}/g, (_, isEnv, name) => {
    if (isEnv) return process.env[name] ?? "";
    return vars[name] ?? "";
  });
}
```

### Assertion Result Type

```typescript
interface AssertionResult {
  passed: boolean;
  assertion: string; // Human-readable description
  expected?: string;
  actual?: string;
  details?: string;
}
```

---

## Alternative Technologies Considered

### Go

**Pros:**

- Single binary distribution
- Fast execution
- Strong concurrency

**Cons:**

- Smaller ecosystem for AG-UI tooling
- More boilerplate for YAML/JSON handling

### Python

**Pros:**

- Quick prototyping
- Good YAML support

**Cons:**

- Distribution complexity (venv, dependencies)
- Slower execution
- Less common for CLI tools in JS ecosystem

### Rust

**Pros:**

- Fast, single binary
- Strong type system

**Cons:**

- Longer development time
- Overkill for MVP

---

## MVP Scope Boundaries

### In Scope

- Single AG-UI endpoint per project
- Sequential test execution
- Header-based authentication
- RE2/JS regex syntax
- Console and exit-code output

### Out of Scope (Future)

- Parallel test execution
- MCP/A2A adapters
- LLM-as-judge assertions
- Semantic text evaluation
- Web UI / dashboard
- Test recording/playback
- Snapshot testing

---

## Success Criteria

1. **Functional:** Run a 3-turn test against a real AG-UI endpoint
2. **Assertions:** All assertion types from spec working
3. **CI Ready:** Exit codes work correctly in GitHub Actions
4. **Developer Experience:** Clear error messages, helpful output
5. **Performance:** < 100ms overhead per turn (excluding network)

---

## Estimated Complexity

| Phase                    | Complexity  | Notes                                |
| ------------------------ | ----------- | ------------------------------------ |
| Phase 1: Foundation      | Low         | Standard CLI/config work             |
| Phase 2: Execution       | Medium      | SSE handling requires care           |
| Phase 3: Data Collection | Medium      | Event parsing, state management      |
| Phase 4: Assertions      | Medium-High | Many edge cases, good error messages |
| Phase 5: Runner          | Medium      | Orchestration, fail-fast logic       |
| Phase 6: Polish          | Low         | Documentation, cleanup               |

---

## Next Steps

1. Initialize TypeScript project with recommended dependencies
2. Implement Phase 1 (config loading, CLI scaffold)
3. Set up a mock AG-UI server for development
4. Iterate through phases, testing against mock server
5. Validate against real AG-UI endpoint
